{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Run on the google colaboratory)Python3 ランタイムがGPUであることを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3828,
     "status": "ok",
     "timestamp": 1576909089739,
     "user": {
      "displayName": "pacific pacifina",
      "photoUrl": "",
      "userId": "10756285699450948021"
     },
     "user_tz": 300
    },
    "id": "2Rx1nR-JZnXh",
    "outputId": "b74947b1-01f5-4d6e-f841-91424b9656e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rF7Ckku6KJwT"
   },
   "source": [
    "# 下のリンクから公式のStyleGANの学習済みモデルをダウンロードし,StyleGAN_LatentEditor/weight_files/tensorflow/ におく\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgszSqtTHQFS"
   },
   "source": [
    "https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eX0Y7lDXK0jc"
   },
   "source": [
    "# 以下のコードでtensorflowの重みをpytorch用に変換する weight_files/pytorch/に作成される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47185,
     "status": "ok",
     "timestamp": 1576915841349,
     "user": {
      "displayName": "pacific pacifina",
      "photoUrl": "",
      "userId": "10756285699450948021"
     },
     "user_tz": 300
    },
    "id": "GSrUTApxG3Bv",
    "outputId": "99fe9eb7-4cd3-47e1-e5ab-76b8be859915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/josefy/mask-remover-nn/Models/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:35: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/josefy/mask-remover-nn/Models/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:75: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/josefy/mask-remover-nn/Models/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:129: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/josefy/mask-remover-nn/Models/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:98: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/josefy/mask-remover-nn/Models/StyleGAN_LatentEditor/dnnlib/tflib/tfutil.py:110: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From <string>:364: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "sd only g_synthesis.blocks.8x8.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only g_synthesis.blocks.16x16.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only g_synthesis.blocks.32x32.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only g_synthesis.blocks.64x64.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only g_synthesis.blocks.128x128.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only g_synthesis.blocks.256x256.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only g_synthesis.blocks.512x512.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only g_synthesis.blocks.1024x1024.conv0_up.intermediate.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only 1024x1024.blur.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only 1024x1024.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
      "sd only 512x512.blur.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only 512x512.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
      "sd only 256x256.blur.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only 256x256.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
      "sd only 128x128.blur.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only 128x128.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
      "sd only 64x64.blur.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only 64x64.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
      "sd only 32x32.blur.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only 32x32.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
      "sd only 16x16.blur.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only 16x16.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n",
      "sd only 8x8.blur.kernel torch.Size([1, 1, 3, 3])\n",
      "sd only 8x8.conv1_down.downscale.blur.kernel torch.Size([1, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "!python weight_convert.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhotVwqfLjao"
   },
   "source": [
    "# [1]潜在変数の推定(Abdal, R., Qin, Y., & Wonka, P. (2019). Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?) \n",
    "latent_W/以下に推定された潜在変数が出力される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dd3jwLubg3ge"
   },
   "outputs": [],
   "source": [
    "!mkdir save_image\n",
    "!mkdir save_image/encode1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 151260,
     "status": "ok",
     "timestamp": 1576916127178,
     "user": {
      "displayName": "pacific pacifina",
      "photoUrl": "",
      "userId": "10756285699450948021"
     },
     "user_tz": 300
    },
    "id": "Mw5ZDAShLtl5",
    "outputId": "96f34f19-00a8-418d-e3cb-de3cc3d66cab"
   },
   "outputs": [],
   "source": [
    "!python encode_image.py   --src_im sample.png --iteration 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nlhm9BUWLy2J"
   },
   "source": [
    "# 推定された潜在変数を元にmorphingを行う\n",
    "morph_result/encode1 以下に出力画像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fH8b83eRhbYh"
   },
   "outputs": [],
   "source": [
    "!mkdir morph_result\n",
    "!mkdir morph_result/encode1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Onh1edyMIVT"
   },
   "outputs": [],
   "source": [
    "!python image_morphing.py --latent_file1 latent_W/0.npy --latent_file2 latent_W/sample.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZGp6o6mhqu6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NIEhWXw-MP3s"
   },
   "source": [
    "# morph画像をgifとして保存\n",
    "save_result以下にgif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_wowlYziIYq"
   },
   "outputs": [],
   "source": [
    "\n",
    "!mkdir save_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7331,
     "status": "ok",
     "timestamp": 1576916275182,
     "user": {
      "displayName": "pacific pacifina",
      "photoUrl": "",
      "userId": "10756285699450948021"
     },
     "user_tz": 300
    },
    "id": "wj4gnA3EMyuS",
    "outputId": "7203fec9-102a-4b62-f3be-9f5ecc11f429"
   },
   "outputs": [],
   "source": [
    "!python make_morphgif.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vnpyNU4NM2n7"
   },
   "source": [
    "# [2]Image Crossover(Abdal, R., Qin, Y., & Wonka, P. (2019). Image2StyleGAN++: How to Edit the Embedded Images? )\n",
    "save_image/crossover/以下に生成画像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vz2Z4qBpiS5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘save_image’: File exists\n",
      "mkdir: cannot create directory ‘save_image/crossover’: File exists\n",
      "mkdir: cannot create directory ‘save_image_noise’: File exists\n",
      "mkdir: cannot create directory ‘save_image_noise/crossover’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir save_image\n",
    "!mkdir save_image/crossover\n",
    "!mkdir save_image_noise\n",
    "!mkdir save_image_noise/crossover\n",
    "\n",
    "!mkdir noise_N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 449880,
     "status": "ok",
     "timestamp": 1576916773574,
     "user": {
      "displayName": "pacific pacifina",
      "photoUrl": "",
      "userId": "10756285699450948021"
     },
     "user_tz": 300
    },
    "id": "yL2T-rzNNJD1",
    "outputId": "c9b3f427-1854-4fc8-afff-8880a9e5f6df",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "Start\n",
      "latent_W iter0: loss -- 7.640584468841553,  loss0 --1.0619629621505737,  loss1 --6.5786213874816895\n",
      "latent_W iter100: loss -- 2.5626165866851807,  loss0 --0.47942104935646057,  loss1 --2.083195447921753\n",
      "latent_W iter200: loss -- 2.2827301025390625,  loss0 --0.36792778968811035,  loss1 --1.9148023128509521\n",
      "latent_W iter300: loss -- 1.919966697692871,  loss0 --0.29937559366226196,  loss1 --1.620591163635254\n",
      "latent_W iter400: loss -- 1.6235483884811401,  loss0 --0.2629452645778656,  loss1 --1.3606030941009521\n",
      "latent_W iter700: loss -- 1.3476066589355469,  loss0 --0.23981890082359314,  loss1 --1.1077877283096313\n",
      "latent_W iter800: loss -- 1.2944039106369019,  loss0 --0.2251114845275879,  loss1 --1.069292426109314\n",
      "latent_W iter900: loss -- 1.2629799842834473,  loss0 --0.2298654317855835,  loss1 --1.0331145524978638\n",
      "latent_W iter1000: loss -- 1.2589540481567383,  loss0 --0.22520816326141357,  loss1 --1.0337458848953247\n",
      "latent_W iter1100: loss -- 1.1928573846817017,  loss0 --0.224113330245018,  loss1 --0.9687440991401672\n",
      "latent_W iter1200: loss -- 1.21649968624115,  loss0 --0.21865125000476837,  loss1 --0.9978484511375427\n",
      "latent_W iter1300: loss -- 1.2001208066940308,  loss0 --0.22457930445671082,  loss1 --0.9755414724349976\n",
      "latent_W iter1400: loss -- 1.126233458518982,  loss0 --0.22079618275165558,  loss1 --0.9054372906684875\n",
      "latent_W iter1500: loss -- 1.1431479454040527,  loss0 --0.21970021724700928,  loss1 --0.9234476685523987\n",
      "latent_W iter1600: loss -- 1.1245136260986328,  loss0 --0.21685360372066498,  loss1 --0.9076600074768066\n",
      "latent_W iter1700: loss -- 1.1273164749145508,  loss0 --0.21691757440567017,  loss1 --0.9103988409042358\n",
      "latent_W iter1800: loss -- 1.1115354299545288,  loss0 --0.2138351947069168,  loss1 --0.8977001905441284\n",
      "latent_W iter1900: loss -- 1.0672600269317627,  loss0 --0.2111414223909378,  loss1 --0.8561185598373413\n",
      "latent_W iter2000: loss -- 1.054917573928833,  loss0 --0.2119435966014862,  loss1 --0.8429739475250244\n",
      "latent_W iter2100: loss -- 1.0641758441925049,  loss0 --0.21795618534088135,  loss1 --0.8462197184562683\n",
      "latent_W iter2200: loss -- 1.0613534450531006,  loss0 --0.21672841906547546,  loss1 --0.8446250557899475\n",
      "latent_W iter2300: loss -- 1.0420931577682495,  loss0 --0.21856960654258728,  loss1 --0.8235235810279846\n",
      "latent_W iter2600: loss -- 1.0187126398086548,  loss0 --0.21109861135482788,  loss1 --0.8076140284538269\n",
      "latent_W iter2700: loss -- 0.9961285591125488,  loss0 --0.20792976021766663,  loss1 --0.7881987690925598\n",
      "latent_W iter2800: loss -- 1.012453317642212,  loss0 --0.21722416579723358,  loss1 --0.7952291965484619\n",
      "latent_W iter2900: loss -- 0.992742657661438,  loss0 --0.21002887189388275,  loss1 --0.782713770866394\n",
      "latent_W iter3000: loss -- 1.0058517456054688,  loss0 --0.21833552420139313,  loss1 --0.787516176700592\n",
      "latent_W iter3100: loss -- 0.9843343496322632,  loss0 --0.20283080637454987,  loss1 --0.7815035581588745\n",
      "latent_W iter3400: loss -- 1.0016436576843262,  loss0 --0.20461997389793396,  loss1 --0.7970236539840698\n",
      "latent_W iter3500: loss -- 0.9637619256973267,  loss0 --0.2027449756860733,  loss1 --0.7610169649124146\n",
      "latent_W iter3600: loss -- 0.9587612152099609,  loss0 --0.20166507363319397,  loss1 --0.7570961713790894\n",
      "latent_W iter3900: loss -- 0.951087236404419,  loss0 --0.20528236031532288,  loss1 --0.7458049058914185\n",
      "latent_W iter4000: loss -- 0.9643596410751343,  loss0 --0.2009933888912201,  loss1 --0.7633662819862366\n",
      "latent_W iter4100: loss -- 0.9438030123710632,  loss0 --0.2085263878107071,  loss1 --0.7352766394615173\n",
      "latent_W iter4200: loss -- 0.9374661445617676,  loss0 --0.20083020627498627,  loss1 --0.7366359233856201\n",
      "latent_W iter4300: loss -- 0.9250339269638062,  loss0 --0.20617224276065826,  loss1 --0.7188616991043091\n",
      "latent_W iter4400: loss -- 0.9411702752113342,  loss0 --0.20922131836414337,  loss1 --0.731948971748352\n"
     ]
    }
   ],
   "source": [
    "!python image_crossover.py --src_im1  source_image/almog_no_mask_white_bkg_6.jpeg --src_im2  source_image/almog_mask_white_bkg_6.jpeg --mask source_image/almog_mask_white_bkg_6_mask.png --iteration 6000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoy9xn_INcTu"
   },
   "source": [
    "# [3] 表情の変換 (Yang, C., Lim, S.-N., & Ai, F. (n.d.). Unconstrained Facial Expression Transfer using Style-based Generator)\n",
    "save_image/exchange/以下に生成画像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6445,
     "status": "ok",
     "timestamp": 1576916917391,
     "user": {
      "displayName": "pacific pacifina",
      "photoUrl": "",
      "userId": "10756285699450948021"
     },
     "user_tz": 300
    },
    "id": "akn_RL8EkMcq",
    "outputId": "d36ba643-93f8-4337-e393-a87efa68b75b"
   },
   "outputs": [],
   "source": [
    "!mkdir save_image/exchange\n",
    "!mkdir save_image/exchange/a\n",
    "!mkdir save_image/exchange/e\n",
    "!mkdir save_image/exchange/result1\n",
    "!mkdir save_image/exchange/result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 243671,
     "status": "ok",
     "timestamp": 1576917193440,
     "user": {
      "displayName": "pacific pacifina",
      "photoUrl": "",
      "userId": "10756285699450948021"
     },
     "user_tz": 300
    },
    "id": "-PB_LOIROC5M",
    "outputId": "620f1316-29fd-4501-f35a-c8f8caf7737b"
   },
   "outputs": [],
   "source": [
    "!python facial_exchange.py --src_im1  source_image/sample.png --src_im2  source_image/0.png  --iteration 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TJEkDZ18OMVB"
   },
   "source": [
    "# [4] 顔属性のmorphing(Shen, Y., Gu, J., Tang, X., & Zhou, B. (2019).Interpreting the Latent Space of GANs for Semantic Face Editing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "論文著者のgithubページからboundariesディレクトリをダウンロードしてStyleGAN_LatentEditor/ 以下に置く https://github.com/ShenYujun/InterFaceGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save_image/boundary/以下に生成画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9sDZz6BCOscs"
   },
   "outputs": [],
   "source": [
    "!mkdir save_image/boundary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JU6hXrrRmFA4"
   },
   "outputs": [],
   "source": [
    "!python semantic_edit.py --latent_file  latent_W/0.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4ZCTqR5ngG2"
   },
   "source": [
    "# [5]自前で用意した画像で試したい方へ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xmRsjATvok4y"
   },
   "outputs": [],
   "source": [
    "!mkdir img\n",
    "!mkdir al_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5VA3Y6jMnqqa"
   },
   "source": [
    "# 入力画像を1024×1024にリサイズしかつalignする必要があります\n",
    "以下のセルでdlibを用いてそれを実行します。\n",
    "imgディレクトリに用意した画像を置きコードを実行するとal_img内にalignされた画像が置かれます。後はsource_imageディレクトリに移して各セルの引数を変更してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16159,
     "status": "ok",
     "timestamp": 1576918270889,
     "user": {
      "displayName": "pacific pacifina",
      "photoUrl": "",
      "userId": "10756285699450948021"
     },
     "user_tz": 300
    },
    "id": "PUOz8gLinWOm",
    "outputId": "227f90ec-c8fc-4c84-fae5-9522e43c4ea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/image2stylegan/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "img/almog_mask_white_bkg_6-Copy1.jpeg\n",
      "img/almog_no_mask_white_bkg_5.jpeg\n",
      "almog_no_mask_white_bkg_5_01.png [(270, 480), (270, 543), (275, 606), (286, 667), (305, 726), (339, 778), (382, 822), (433, 858), (499, 867), (569, 849), (627, 803), (676, 751), (709, 694), (725, 632), (731, 567), (733, 502), (730, 436), (276, 394), (300, 362), (339, 347), (381, 346), (423, 360), (502, 347), (548, 329), (597, 324), (645, 337), (681, 369), (467, 420), (465, 465), (463, 509), (460, 554), (430, 601), (451, 607), (474, 611), (499, 602), (524, 590), (324, 454), (348, 433), (382, 430), (417, 447), (383, 459), (349, 462), (539, 437), (568, 415), (604, 412), (634, 428), (607, 443), (570, 443), (399, 711), (425, 685), (454, 669), (479, 674), (501, 665), (538, 676), (582, 695), (543, 725), (509, 736), (484, 740), (458, 739), (428, 734), (415, 709), (456, 693), (481, 694), (504, 690), (562, 695), (504, 697), (481, 700), (457, 700)]\n",
      "img/almog_mask_white_bkg_1-Copy1.jpeg\n",
      "almog_mask_white_bkg_1-Copy1_01.png [(362, 473), (361, 518), (365, 563), (370, 609), (385, 651), (413, 687), (448, 715), (489, 737), (535, 741), (584, 732), (624, 704), (657, 672), (684, 637), (697, 593), (700, 548), (702, 504), (699, 459), (383, 426), (400, 398), (429, 380), (463, 378), (495, 388), (541, 386), (574, 373), (611, 370), (645, 385), (666, 414), (521, 430), (521, 465), (521, 498), (521, 533), (489, 560), (506, 567), (524, 572), (543, 567), (561, 559), (420, 446), (437, 436), (458, 434), (482, 446), (459, 450), (438, 452), (565, 441), (584, 428), (606, 428), (626, 436), (607, 444), (586, 444), (457, 631), (483, 622), (506, 615), (523, 620), (539, 615), (562, 620), (590, 626), (562, 631), (540, 633), (523, 634), (505, 633), (483, 632), (467, 630), (507, 633), (524, 635), (540, 632), (577, 626), (539, 613), (523, 615), (506, 614)]\n",
      "img/almog_no_mask_white_bkg_6-Copy1.jpeg\n",
      "almog_no_mask_white_bkg_6-Copy1_01.png [(288, 459), (288, 518), (295, 575), (306, 632), (325, 687), (356, 737), (398, 779), (445, 817), (506, 828), (568, 813), (623, 773), (670, 725), (703, 671), (721, 611), (730, 550), (732, 488), (732, 426), (301, 393), (322, 359), (359, 343), (399, 341), (438, 355), (522, 342), (565, 324), (612, 321), (656, 336), (685, 371), (483, 411), (481, 455), (479, 498), (478, 543), (444, 575), (465, 584), (488, 590), (512, 579), (535, 567), (347, 438), (372, 419), (404, 417), (435, 435), (405, 445), (372, 448), (547, 426), (577, 403), (609, 403), (637, 418), (612, 432), (579, 433), (413, 659), (441, 644), (471, 636), (494, 640), (519, 633), (554, 638), (596, 645), (557, 679), (524, 693), (497, 697), (471, 696), (443, 688), (428, 660), (472, 655), (495, 657), (521, 652), (578, 648), (521, 659), (495, 663), (471, 661)]\n",
      "img/josef_with_white_mask.jpeg\n",
      "img/almog_no_mask_white_bkg_1-Copy1.jpeg\n",
      "almog_no_mask_white_bkg_1-Copy1_01.png [(365, 456), (363, 497), (365, 538), (371, 581), (388, 620), (416, 655), (445, 690), (479, 727), (521, 737), (564, 727), (604, 695), (637, 658), (667, 619), (687, 576), (694, 528), (697, 479), (698, 429), (377, 422), (391, 396), (419, 385), (448, 386), (476, 395), (530, 389), (562, 374), (597, 368), (632, 378), (656, 403), (506, 436), (505, 473), (504, 509), (504, 546), (472, 555), (489, 564), (509, 571), (532, 560), (553, 550), (409, 448), (429, 437), (452, 437), (474, 450), (451, 454), (428, 454), (554, 442), (575, 428), (598, 425), (618, 434), (601, 443), (577, 445), (438, 595), (465, 591), (492, 589), (514, 593), (537, 587), (572, 586), (608, 588), (576, 628), (543, 647), (518, 651), (494, 649), (465, 633), (449, 599), (493, 600), (515, 602), (537, 597), (598, 591), (541, 628), (517, 632), (494, 628)]\n",
      "img/josef_no_mask_profile-Copy1.jpeg\n",
      "josef_no_mask_profile-Copy1_01.png [(373, 504), (359, 553), (358, 607), (373, 665), (386, 721), (396, 775), (410, 836), (434, 883), (485, 900), (561, 902), (647, 878), (725, 839), (794, 784), (840, 711), (863, 622), (868, 536), (870, 452), (348, 421), (352, 392), (373, 375), (402, 374), (434, 384), (472, 373), (528, 345), (590, 330), (655, 347), (705, 386), (452, 428), (435, 464), (415, 500), (394, 537), (395, 599), (413, 611), (437, 617), (468, 609), (503, 600), (377, 469), (387, 444), (417, 439), (443, 457), (418, 473), (391, 478), (547, 447), (571, 417), (609, 416), (645, 436), (612, 450), (576, 452), (408, 730), (406, 692), (421, 677), (442, 680), (469, 672), (521, 684), (581, 717), (528, 741), (482, 750), (453, 755), (431, 755), (413, 745), (419, 725), (425, 702), (445, 702), (472, 700), (561, 715), (475, 717), (448, 719), (427, 717)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img/ifim_with_mask.jpeg\n",
      "img/almog_mask_white_bkg_5.jpeg\n"
     ]
    }
   ],
   "source": [
    "!python align_images.py img/ al_img/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXgS_GYhqixI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QOPqfIIAqjWe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEAUJM22qjpN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20733,
     "status": "ok",
     "timestamp": 1576915708273,
     "user": {
      "displayName": "pacific pacifina",
      "photoUrl": "",
      "userId": "10756285699450948021"
     },
     "user_tz": 300
    },
    "id": "M911q2vTSheX",
    "outputId": "9a7a3cd0-7c22-4427-fe4d-79cc41eb4e13"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMMn7z2Vf8kT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4810,
     "status": "ok",
     "timestamp": 1576915762398,
     "user": {
      "displayName": "pacific pacifina",
      "photoUrl": "",
      "userId": "10756285699450948021"
     },
     "user_tz": 300
    },
    "id": "uU56IDY-gLl4",
    "outputId": "af0e48be-6887-4a8c-ac45-9456d641fcd8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1576915783627,
     "user": {
      "displayName": "pacific pacifina",
      "photoUrl": "",
      "userId": "10756285699450948021"
     },
     "user_tz": 300
    },
    "id": "OKMfdnMDgOnJ",
    "outputId": "435b5aaa-9bd8-4347-d114-295049a29257"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bK2Dcm43gSwi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "StyleGAN_editor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
